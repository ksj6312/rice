## Streamlit 대시보드 구현 계획 (페이즈 단위)

### 개요
- 데이터: `서울교통공사_지하철혼잡도정보_20250930.csv`
- 형태: (식별 컬럼) + (05:30~00:30 30분 단위 혼잡도 컬럼 다수, wide)
- 목표: 요일/호선/역/방향/시간대별 혼잡도 분석 대시보드(Streamlit)

---

### 페이즈 0) 프로젝트 뼈대 결정 (0.5일)
- 결정사항
  - 실행/배포: 로컬 또는 Streamlit Community Cloud
  - 파이썬/라이브러리: `pandas`, 시각화(`altair` 또는 `plotly`), `pyarrow`(옵션)
  - 데이터 갱신 방식: (A) 리포에 CSV 포함 (B) 앱 업로드 (C) 폴더 스캔
- 산출물
  - 폴더 구조: `app.py`, `pages/`, `src/`, `data/`
  - `requirements.txt` 초안

---

### 페이즈 1) 데이터 로딩/정제 모듈 (0.5~1일)
- 작업
  - CSV 인코딩 처리(깨짐 방지: CP949 가능성 고려)
  - 컬럼 표준화: 요일/호선/역번호/역명/방향
  - 혼잡도 값 파싱(공백 제거, 숫자 변환)
- 핵심 변환
  - 시간 컬럼(05:30~00:30)을 long 포맷으로 변환
  - 목표 스키마: `요일,호선,역번호,역명,방향,시간,혼잡도`
- Streamlit
  - `@st.cache_data`로 로딩/변환 캐싱
- 산출물
  - `load_data()`, `to_long_format()` 함수

---

### 페이즈 2) KPI/집계 함수 구축 (0.5~1일)
- 지표(예시)
  - 피크 혼잡도 / 피크 시간
  - 시간대 평균(출근/퇴근/심야 등)
  - TOP-N(역/호선)
  - 방향(상/하 또는 내/외선) 비교
- 산출물
  - `compute_kpis(df_long, filters)`
  - `aggregate_for_line()`, `aggregate_for_heatmap()`, `top_n_stations()` 등 순수 함수

---

### 페이즈 3) MVP(개요 페이지 1개) 구현 (1일)
- UI
  - 사이드바 필터: 요일, 호선, 역 검색, 방향, 시간대
- 시각화(최소 구성)
  - KPI 카드: 피크/평균/피크 시간
  - 라인차트: 시간대별 혼잡도(선택 역 또는 전체 평균)
  - 막대차트: 가장 혼잡한 역 TOP10
- 산출물
  - `app.py` 1페이지 MVP

---

### 페이즈 4) 멀티페이지 확장 (0.5~1일)
- 페이지(예시)
  - 노선별 히트맵: 시간 × 호선
  - 역 상세: 요일/방향 비교 + 피크 구간 강조
- 산출물
  - `pages/` 2~3개 + 공통 UI/유틸 `src/` 분리

---

### 페이즈 5) 품질/해석/UX 보강 (0.5~1일)
- 데이터 품질
  - 0값/결측 의미 정리 및 처리 규칙 문서화
  - 100% 초과 가능 여부/표시 정책(범례/색상)
- UX
  - 툴팁/주석(혼잡도 정의, 해석 주의사항)
  - 다운로드 버튼(필터 적용 결과 CSV)
- 성능
  - 사전집계/캐싱 강화, 불필요한 재계산 최소화
- 산출물
  - “설명 가능한” 대시보드 + 빠른 반응성

---

### 페이즈 6) 배포/운영 (0.5일)
- 배포
  - 실행 방법 문서화(`streamlit run app.py`)
  - `requirements.txt` 확정
- 운영
  - 새 CSV 반영 절차(업로드/폴더 스캔/교체)
- 산출물
  - 배포 URL(선택) + 실행/갱신 가이드 1p

---

### 오픈 질문(결정 필요)
- 시각화 라이브러리: Altair vs Plotly
- 데이터 갱신 방식: 포함/업로드/폴더스캔
- 시간대 구간 정의: 출근/퇴근/심야 범위 및 임계치(색상 구간)

