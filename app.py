"""
ì„œìš¸ ì§€í•˜ì²  í˜¼ì¡ë„ ëŒ€ì‹œë³´ë“œ
ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
"""

import streamlit as st
import pandas as pd
from src.data_loader import load_data, to_long_format, get_csv_info

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì„œìš¸ ì§€í•˜ì²  í˜¼ì¡ë„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸš‡",
    layout="wide"
)

# íƒ€ì´í‹€
st.title("ğŸš‡ ì„œìš¸ ì§€í•˜ì²  í˜¼ì¡ë„ ëŒ€ì‹œë³´ë“œ")

# ë°ì´í„° ë¡œë”©
try:
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        # Wide í¬ë§· ë¡œë”©
        df_wide = load_data()
        
        # Long í¬ë§· ë³€í™˜
        df_long = to_long_format(df_wide)
        
        # íŒŒì¼ ì •ë³´
        file_info = get_csv_info()
    
    # ì„±ê³µ ë©”ì‹œì§€
    st.success("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    
    # ë°ì´í„° ìš”ì•½
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ë ˆì½”ë“œ ìˆ˜", f"{len(df_long):,}")
    
    with col2:
        st.metric("ì—­ ìˆ˜", df_long['ì—­ëª…'].nunique())
    
    with col3:
        st.metric("í˜¸ì„  ìˆ˜", df_long['í˜¸ì„ '].nunique())
    
    with col4:
        st.metric("ì‹œê°„ëŒ€ ìˆ˜", df_long['ì‹œê°„'].nunique())
    
    # í˜ì´ì¦ˆ 1 ì™„ë£Œ ì•ˆë‚´
    st.info("""
    âœ… **í˜ì´ì¦ˆ 1 ì™„ë£Œ**: ë°ì´í„° ë¡œë”© ë° ì •ì œ ëª¨ë“ˆ êµ¬í˜„ ì™„ë£Œ
    - CSV ì¸ì½”ë”© ì²˜ë¦¬ (CP949) âœ“
    - ì»¬ëŸ¼ í‘œì¤€í™” âœ“
    - Wide â†’ Long í¬ë§· ë³€í™˜ âœ“
    - Streamlit ìºì‹± ì ìš© âœ“
    
    **ë‹¤ìŒ ë‹¨ê³„ (í˜ì´ì¦ˆ 2)**: KPI/ì§‘ê³„ í•¨ìˆ˜ êµ¬ì¶•
    """)

    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Long í¬ë§·)"):
        st.dataframe(df_long.head(20), width='stretch')
        
        st.subheader("ì»¬ëŸ¼ ì •ë³´")
        col_info = pd.DataFrame({
            'ì»¬ëŸ¼ëª…': df_long.columns,
            'íƒ€ì…': df_long.dtypes.values,
            'Null ê°œìˆ˜': df_long.isnull().sum().values,
            'ê³ ìœ ê°’ ê°œìˆ˜': [df_long[col].nunique() for col in df_long.columns]
        })
        st.dataframe(col_info, width='stretch')
    
    # íŒŒì¼ ì •ë³´
    with st.expander("ğŸ“ íŒŒì¼ ì •ë³´"):
        if file_info:
            st.write(f"**íŒŒì¼ëª…**: {file_info.get('file_name', 'N/A')}")
            st.write(f"**íŒŒì¼ í¬ê¸°**: {file_info.get('file_size_mb', 0)} MB")
            st.write(f"**ê²½ë¡œ**: {file_info.get('file_path', 'N/A')}")
    
    # í”„ë¡œì íŠ¸ êµ¬ì¡° ì•ˆë‚´
    with st.expander("ğŸ—‚ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°"):
        st.code("""
rice-1/
â”œâ”€â”€ app.py                 # ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ (í˜„ì¬ íŒŒì¼)
â”œâ”€â”€ pages/                 # ë©€í‹°í˜ì´ì§€ìš© (í˜ì´ì¦ˆ 4)
â”œâ”€â”€ src/                   # ë°ì´í„° ë¡œë”©/ì§‘ê³„ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ data_loader.py     # ë°ì´í„° ë¡œë”©/ì •ì œ âœ…
â”‚   â””â”€â”€ aggregations.py    # KPI/ì§‘ê³„ í•¨ìˆ˜ (í˜ì´ì¦ˆ 2)
â”œâ”€â”€ data/                  # CSV ë°ì´í„° ì €ì¥
â”‚   â””â”€â”€ ì„œìš¸êµí†µê³µì‚¬_ì§€í•˜ì² í˜¼ì¡ë„ì •ë³´_20250930.csv
â””â”€â”€ requirements.txt       # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
        """, language="text")

except FileNotFoundError as e:
    st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
except Exception as e:
    st.error(f"âŒ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.exception(e)

import pandas as pd
from src.aggregations import (
    compute_kpis, 
    aggregate_for_line, 
    aggregate_for_heatmap,
    top_n_stations,
    compare_by_weekday,
    compare_by_direction,
    get_congestion_stats
)

st.divider()

# ============================================================================
# í˜ì´ì¦ˆ 2 ê²€ì¦: KPI/ì§‘ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
# ============================================================================
st.subheader("ğŸ§ª í˜ì´ì¦ˆ 2 ê²€ì¦: KPI/ì§‘ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")

with st.expander("ğŸ“Š KPI ê³„ì‚° í…ŒìŠ¤íŠ¸", expanded=True):
    st.write("**ì „ì²´ ë°ì´í„° KPI:**")
    kpis = compute_kpis(df_long, {})
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ìµœëŒ€ í˜¼ì¡ë„", f"{kpis['peak_congestion']}%")
    with col2:
        st.metric("í”¼í¬ ì‹œê°„", kpis['peak_time'])
    with col3:
        st.metric("í‰ê·  í˜¼ì¡ë„", f"{kpis['avg_congestion']}%")
    with col4:
        st.metric("ë ˆì½”ë“œ ìˆ˜", f"{kpis['total_records']:,}")

with st.expander("ğŸš‡ í˜¸ì„ ë³„ ì§‘ê³„"):
    line_agg = aggregate_for_line(df_long)
    st.dataframe(line_agg, hide_index=True, width='stretch')

with st.expander("ğŸ† í˜¼ì¡í•œ ì—­ TOP 10"):
    top_stations = top_n_stations(df_long, n=10, by='max')
    st.dataframe(top_stations, hide_index=True, width='stretch')

with st.expander("ğŸ“… ìš”ì¼ë³„ ë¹„êµ (í‰ì¼ vs ì£¼ë§)"):
    weekday_compare = compare_by_weekday(df_long)
    st.dataframe(weekday_compare, hide_index=True, width='stretch')

with st.expander("â†”ï¸ ë°©í–¥ë³„ ë¹„êµ"):
    direction_compare = compare_by_direction(df_long)
    st.dataframe(direction_compare, hide_index=True, width='stretch')

with st.expander("ğŸ“ˆ í˜¼ì¡ë„ ë¶„í¬ í†µê³„"):
    stats = get_congestion_stats(df_long)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("í‰ê· ", f"{stats['mean']}%")
        st.metric("ìµœì†Œê°’", f"{stats['min']}%")
    with col2:
        st.metric("í‘œì¤€í¸ì°¨", f"{stats['std']}%")
        st.metric("1ì‚¬ë¶„ìœ„", f"{stats['q25']}%")
    with col3:
        st.metric("ì¤‘ì•™ê°’", f"{stats['q50']}%")
        st.metric("3ì‚¬ë¶„ìœ„", f"{stats['q75']}%")
    with col4:
        st.metric("ìµœëŒ€ê°’", f"{stats['max']}%")

st.divider()

# ê°œë°œ ë¡œë“œë§µ
st.subheader("ğŸ“‹ ê°œë°œ ë¡œë“œë§µ")
col1, col2, col3 = st.columns(3)

with col1:
    st.success("âœ… **í˜ì´ì¦ˆ 0**: í”„ë¡œì íŠ¸ ë¼ˆëŒ€")
    st.caption("í´ë” êµ¬ì¡°, requirements.txt")

with col2:
    st.success("âœ… **í˜ì´ì¦ˆ 1**: ë°ì´í„° ë¡œë”©/ì •ì œ")
    st.caption("CSV ë¡œë”©, Long í¬ë§· ë³€í™˜")

with col3:
    st.success("âœ… **í˜ì´ì¦ˆ 2**: KPI/ì§‘ê³„")
    st.caption("í”¼í¬ í˜¼ì¡ë„, TOP-N ì—­")
